{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9d9e30",
   "metadata": {},
   "source": [
    "# 1. Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9577cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded cleaned data: (21158869, 14)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train a CatBoost model for UK housing prices on 2016â€“2017 data.\n",
    "\n",
    "Steps:\n",
    "1. Load cleaned data\n",
    "2. Filter to years 2016â€“2017\n",
    "3. Optionally keep only the newest N rows\n",
    "4. Train/val/test split (80 / 10 / 10)\n",
    "5. Train CatBoostRegressor with categorical features\n",
    "6. Evaluate on val + test\n",
    "7. Save model\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ------------------------------------------------------------\n",
    "CLEANED_PATH = \"cleaned_uk_housing2.csv\"\n",
    "TARGET_COL = \"price\"\n",
    "\n",
    "USE_NEWEST_ONLY = True       # set to False if you want ALL 2016â€“2017 rows\n",
    "MAX_ROWS = 1000000          # newest N rows within 2016â€“2017\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# ------------------------------------------------------------\n",
    "# 1. LOAD CLEANED DATA\n",
    "# ------------------------------------------------------------\n",
    "if not os.path.exists(CLEANED_PATH):\n",
    "    raise FileNotFoundError(f\"File not found: {CLEANED_PATH}\")\n",
    "\n",
    "df = pd.read_csv(CLEANED_PATH)\n",
    "print(f\"âœ… Loaded cleaned data: {df.shape}\")\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COL}' not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0847e",
   "metadata": {},
   "source": [
    "# 2. FEATURE ENGINEERING + FILTER (2016â€“2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d029dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rows after year filter (2016â€“2017): (1170866, 10)\n",
      "âœ… Using newest 1,000,000 rows from 2016â€“2017: (1000000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure date_of_transfer exists and build numeric timestamp\n",
    "if \"date_of_transfer\" not in df.columns:\n",
    "    raise ValueError(\"Column 'date_of_transfer' not found in the dataset.\")\n",
    "\n",
    "df[\"date_of_transfer\"] = pd.to_datetime(df[\"date_of_transfer\"], errors=\"coerce\")\n",
    "df[\"date_numeric\"] = df[\"date_of_transfer\"].astype(\"int64\") // 10**9\n",
    "\n",
    "# Year / month\n",
    "if \"year\" not in df.columns:\n",
    "    df[\"year\"] = df[\"date_of_transfer\"].dt.year\n",
    "if \"month\" not in df.columns:\n",
    "    df[\"month\"] = df[\"date_of_transfer\"].dt.month\n",
    "\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "\n",
    "# Choose features for the model\n",
    "selected_features = [\n",
    "    \"district\",\n",
    "    \"town\",\n",
    "    \"county\",\n",
    "    \"month\",\n",
    "    \"year\",\n",
    "    \"property_type\",\n",
    "    \"tenure\",\n",
    "    \"new_build_flag\",\n",
    "    \"date_numeric\",\n",
    "]\n",
    "\n",
    "cols_to_use = [c for c in selected_features if c in df.columns] + [TARGET_COL]\n",
    "df_small = df[cols_to_use].copy()\n",
    "\n",
    "# Ensure new_build_flag is categorical if present\n",
    "if \"new_build_flag\" in df_small.columns:\n",
    "    df_small[\"new_build_flag\"] = df_small[\"new_build_flag\"].astype(\"object\")\n",
    "\n",
    "# Filter to 2016â€“2017\n",
    "df_small = df_small[df_small[\"year\"].isin([2016, 2017])].copy()\n",
    "print(f\"âœ… Rows after year filter (2016â€“2017): {df_small.shape}\")\n",
    "\n",
    "# Sort oldest â†’ newest using year, month, and date_numeric as tie-breaker\n",
    "sort_cols = [c for c in [\"year\", \"month\", \"date_numeric\"] if c in df_small.columns]\n",
    "df_small = df_small.sort_values(by=sort_cols, ascending=True)\n",
    "\n",
    "# Optionally keep only the newest MAX_ROWS\n",
    "if USE_NEWEST_ONLY and len(df_small) > MAX_ROWS:\n",
    "    df_small = df_small.tail(MAX_ROWS).reset_index(drop=True)\n",
    "    print(f\"âœ… Using newest {MAX_ROWS:,} rows from 2016â€“2017: {df_small.shape}\")\n",
    "else:\n",
    "    df_small = df_small.reset_index(drop=True)\n",
    "    print(\"âœ… Using all rows within 2016â€“2017:\", df_small.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99e6cc",
   "metadata": {},
   "source": [
    "# 3. TRAIN / VAL / TEST SPLIT (80 / 10 / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e18507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SPLIT SUMMARY ===\n",
      "Train: (711120, 9)\n",
      "Val:   (88880, 9)\n",
      "Test:  (200000, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_small.drop(columns=[TARGET_COL])\n",
    "y = df_small[TARGET_COL]\n",
    "\n",
    "# 80% train+val, 20% test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Within trainval, make explicit val chunk (~10% overall)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1111, random_state=RANDOM_STATE\n",
    ")\n",
    "# 0.1111 of 0.8 â‰ˆ 0.0889, so roughly 80 / 10 / 10\n",
    "\n",
    "print(\"\\n=== SPLIT SUMMARY ===\")\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:  \", X_val.shape)\n",
    "print(\"Test: \", X_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c4b60",
   "metadata": {},
   "source": [
    "# 4. CATEGORICAL FEATURES FOR CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02860af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical features for CatBoost: ['district', 'town', 'county', 'property_type', 'tenure', 'new_build_flag']\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns: CatBoost can handle them natively\n",
    "cat_feature_names = []\n",
    "for col in [\"district\", \"town\", \"county\", \"property_type\", \"tenure\", \"new_build_flag\"]:\n",
    "    if col in X_train.columns:\n",
    "        cat_feature_names.append(col)\n",
    "\n",
    "print(\"\\nCategorical features for CatBoost:\", cat_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc343ae",
   "metadata": {},
   "source": [
    "# 5. TRAIN CATBOOST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dd42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training CatBoost on raw price (no log-transform)...\n",
      "0:\tlearn: 91056.1892742\ttest: 91303.9437515\tbest: 91303.9437515 (0)\ttotal: 248ms\tremaining: 12m 22s\n",
      "100:\tlearn: 59275.4400136\ttest: 59188.2923955\tbest: 59188.2923955 (100)\ttotal: 20.7s\tremaining: 9m 53s\n",
      "200:\tlearn: 58366.7779498\ttest: 58297.6319716\tbest: 58297.6319716 (200)\ttotal: 40.6s\tremaining: 9m 25s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      6\u001b[39m model = CatBoostRegressor(\n\u001b[32m      7\u001b[39m     loss_function=\u001b[33m\"\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     eval_metric=\u001b[33m\"\u001b[39m\u001b[33mRMSE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m     \u001b[38;5;66;03m# training logs off; fit() can still override with verbose\u001b[39;00m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸš€ Training CatBoost on raw price (no log-transform)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_feature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# print every 100 iterations\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tijl0\\Desktop\\Machine Learning\\extra\\.venv\\Lib\\site-packages\\catboost\\core.py:5873\u001b[39m, in \u001b[36mCatBoostRegressor.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5872\u001b[39m     CatBoostRegressor._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5874\u001b[39m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5875\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5876\u001b[39m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tijl0\\Desktop\\Machine Learning\\extra\\.venv\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tijl0\\Desktop\\Machine Learning\\extra\\.venv\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=3000,\n",
    "    subsample=0.8,\n",
    "    random_state=RANDOM_STATE,\n",
    "    l2_leaf_reg=3.0,\n",
    "    od_type=\"Iter\",   # early stopping type\n",
    "    od_wait=100,      # rounds to wait before stopping\n",
    "    use_best_model=True,\n",
    "    verbose=False     # training logs off; fit() can still override with verbose\n",
    ")\n",
    "print(\"\\n Training CatBoost on raw price (no log-transform)...\")\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=(X_val, y_val),\n",
    "    cat_features=cat_feature_names,\n",
    "    verbose=100  # print every 100 iterations\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830f2e7",
   "metadata": {},
   "source": [
    "# 6. EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c4fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation (CatBoost) ===\n",
      "MAE:  Â£42,425.34\n",
      "RMSE: Â£57,089.25\n",
      "RÂ²:   0.6281\n",
      "\n",
      "=== TEST (CatBoost) ===\n",
      "MAE:  Â£42,309.31\n",
      "RMSE: Â£56,954.98\n",
      "RÂ²:   0.6281\n",
      "\n",
      "Average actual house price (test): Â£198,689.62\n",
      "MAE â‰ˆ 21.29% of average price.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def eval_regression(y_true, y_pred, name=\"\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"MAE:  Â£{mae:,.2f}\")\n",
    "    print(f\"RMSE: Â£{rmse:,.2f}\")\n",
    "    print(f\"RÂ²:   {r2:.4f}\")\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Validation\n",
    "val_pred = model.predict(X_val)\n",
    "eval_regression(y_val, val_pred, \"Validation (CatBoost)\")\n",
    "\n",
    "# Test\n",
    "test_pred = model.predict(X_test)\n",
    "mae_test, rmse_test, r2_test = eval_regression(y_test, test_pred, \"TEST (CatBoost)\")\n",
    "\n",
    "avg_price = y_test.mean()\n",
    "mae_percent = (mae_test / avg_price) * 100\n",
    "print(f\"\\nAverage actual house price (test): Â£{avg_price:,.2f}\")\n",
    "print(f\"MAE â‰ˆ {mae_percent:.2f}% of average price.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc7d9f",
   "metadata": {},
   "source": [
    "# 7 Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a2fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Saved CatBoost model to: uk_housing_price_catboost.pkl\n",
      "ðŸ’¾ Saved CatBoost model in native format to: uk_housing_price_catboost.cbm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save as Pickle\n",
    "PKL_PATH = \"uk_housing_price_catboost.pkl\"\n",
    "with open(PKL_PATH, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Saved CatBoost model to: {PKL_PATH}\")\n",
    "\n",
    "# Also save native CatBoost format (optional but recommended)\n",
    "CBM_PATH = \"uk_housing_price_catboost.cbm\"\n",
    "model.save_model(CBM_PATH)\n",
    "print(f\"ðŸ’¾ Saved CatBoost model in native format to: {CBM_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
