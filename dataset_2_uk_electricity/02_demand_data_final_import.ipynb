{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c5c164",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c52f6c",
   "metadata": {},
   "source": [
    "We importeren de nodige libraries voor data analyse (pandas, numpy), visualisatie (matplotlib, seaborn) en tijdreeksverwerking. De plotting settings zorgen voor consistente en professionele grafieken doorheen de hele notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c392f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a977beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Files found:\n",
      "  - demanddata_2001.csv -> variable df_2001: 17520 rows\n",
      "  - demanddata_2002.csv -> variable df_2002: 17520 rows\n",
      "  - demanddata_2003.csv -> variable df_2003: 17520 rows\n",
      "  - demanddata_2004.csv -> variable df_2004: 17568 rows\n",
      "  - demanddata_2005.csv -> variable df_2005: 17520 rows\n",
      "  - demanddata_2006.csv -> variable df_2006: 17520 rows\n",
      "  - demanddata_2007.csv -> variable df_2007: 17520 rows\n",
      "  - demanddata_2008.csv -> variable df_2008: 17568 rows\n",
      "  - demanddata_2009.csv -> variable df_2009: 17520 rows\n",
      "  - demanddata_2010.csv -> variable df_2010: 17520 rows\n",
      "  - demanddata_2011.csv -> variable df_2011: 17520 rows\n",
      "  - demanddata_2012.csv -> variable df_2012: 17568 rows\n",
      "  - demanddata_2013.csv -> variable df_2013: 17520 rows\n",
      "  - demanddata_2014.csv -> variable df_2014: 17520 rows\n",
      "  - demanddata_2015.csv -> variable df_2015: 17520 rows\n",
      "  - demanddata_2016.csv -> variable df_2016: 17568 rows\n",
      "  - demanddata_2017.csv -> variable df_2017: 17520 rows\n",
      "  - demanddata_2018.csv -> variable df_2018: 17520 rows\n",
      "  - demanddata_2019.csv -> variable df_2019: 17520 rows\n",
      "  - demanddata_2020.csv -> variable df_2020: 17568 rows\n",
      "  - demanddata_2021.csv -> variable df_2021: 17520 rows\n",
      "  - demanddata_2022.csv -> variable df_2022: 17520 rows\n",
      "  - demanddata_2023.csv -> variable df_2023: 17520 rows\n",
      "  - demanddata_2024.csv -> variable df_2024: 17568 rows\n",
      "  - demanddata_2025.csv -> variable df_2025: 13246 rows\n",
      "\n",
      "‚úÖ Total combined rows: 434014\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Pas pad aan indien nodig\n",
    "data_dir = Path('../data/demand')\n",
    "if not data_dir.exists():\n",
    "    data_dir = Path('../data/')\n",
    "if not data_dir.exists():\n",
    "    data_dir = Path('../data/demand/')\n",
    "\n",
    "csv_files = sorted(data_dir.glob('*.csv'))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {data_dir.resolve()}\")\n",
    "\n",
    "loaded = []\n",
    "print(\"‚úÖ Files found:\")\n",
    "for f in csv_files:\n",
    "    df_tmp = pd.read_csv(f)\n",
    "    loaded.append((f.name, df_tmp))\n",
    "    # Probeer jaartal uit bestandsnaam te halen en maak variable df_YYYY\n",
    "    m = re.search(r'(\\d{4})', f.stem)\n",
    "    if m:\n",
    "        year = m.group(1)\n",
    "        var_name = f\"df_{year}\"\n",
    "        globals()[var_name] = df_tmp\n",
    "        print(f\"  - {f.name} -> variable {var_name}: {len(df_tmp)} rows\")\n",
    "    else:\n",
    "        print(f\"  - {f.name}: {len(df_tmp)} rows (no year in filename)\")\n",
    "\n",
    "# Samengevoegd dataframe (gebruik df_raw of vervang later bestaande concat)\n",
    "df_raw = pd.concat([t[1] for t in loaded], ignore_index=True)\n",
    "print(f\"\\n‚úÖ Total combined rows: {len(df_raw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3257f7",
   "metadata": {},
   "source": [
    "We laden alle jaarlijkse CSV-bestanden in vanuit de data directory. Elk bestand bevat half-uurlijkse metingen van elektriciteitsverbruik en gerelateerde variabelen. Let op dat schrikkeljaren (2004, 2008, 2012, 2016, 2020, 2024) 17568 rijen hebben in plaats van 17520 omdat deze jaren een extra dag bevatten (366 dagen √ó 48 metingen per dag). Het jaar 2025 bevat slechts 13246 rijen omdat we enkel data tot begin oktober hebben. In totaal hebben we 434014 datapunten over een periode van bijna 25 jaar (2001-2025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478750f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined dataframe: 434014 rows x 22 columns\n",
      "\n",
      "Date range: 2001-01-01 00:00:00 to 2025-10-03 00:00:00 (column: SETTLEMENT_DATE)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Prefer the already created df_raw (from the loader cell)\n",
    "if 'df_raw' in globals():\n",
    "    df = globals()['df_raw'].copy()\n",
    "else:\n",
    "    # Zoek globale dataframes zoals df_YYYY\n",
    "    candidate_dfs = [v for k, v in globals().items() if re.match(r'^df_\\d{4}$', k) and isinstance(v, pd.DataFrame)]\n",
    "    if candidate_dfs:\n",
    "        df = pd.concat(candidate_dfs, ignore_index=True)\n",
    "    else:\n",
    "        # Fallback: lees alle CSVs uit Data/Demand of ../data/demand\n",
    "        data_dir = Path('Data/Demand')\n",
    "        if not data_dir.exists():\n",
    "            data_dir = Path('../data/demand')\n",
    "        if not data_dir.exists():\n",
    "            data_dir = Path('./data/demand')\n",
    "        csv_files = sorted(data_dir.glob('*.csv'))\n",
    "        if not csv_files:\n",
    "            raise FileNotFoundError(f\"No CSV files found in {data_dir.resolve()}\")\n",
    "        df_list = [pd.read_csv(f) for f in csv_files]\n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(f\"‚úÖ Combined dataframe: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "\n",
    "# Try to detect date column (settlement_date case-insensitive) and show range if possible\n",
    "date_col = None\n",
    "for c in df.columns:\n",
    "    if 'settlement' in c.lower() and 'date' in c.lower():\n",
    "        date_col = c\n",
    "        break\n",
    "if date_col is None:\n",
    "    # fallback: any column name containing 'date'\n",
    "    date_candidates = [c for c in df.columns if 'date' in c.lower()]\n",
    "    date_col = date_candidates[0] if date_candidates else None\n",
    "\n",
    "if date_col is not None:\n",
    "    try:\n",
    "        date_series = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        print(f\"\\nDate range: {date_series.min()} to {date_series.max()} (column: {date_col})\")\n",
    "    except Exception:\n",
    "        print(f\"\\nDate column detected: {date_col} (could not convert to datetime for range)\")\n",
    "else:\n",
    "    print(\"\\nGeen date-kolom gevonden om datum-range te tonen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce42386",
   "metadata": {},
   "source": [
    "We verifi√´ren dat de data correct is ingeladen door de dimensies en het datumbereik te controleren. De dataset bevat 22 kolommen met verschillende metingen: van nationale vraag (ND) tot embedded generatie en interconnector flows. De settlement_date kolom toont aan dat we data hebben van begin 2001 tot oktober 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78533dfa",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "Om de data toegankelijker te maken en consistentie te waarborgen, passen we een standaard naming convention toe: alle kolomnamen worden lowercase en spaties worden vervangen door underscores. Dit maakt de code leesbaarder en voorkomt potenti√´le errors bij het refereren naar kolommen.\n",
    "\n",
    "### 2.1 Kolommen hernoemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ccc5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nieuwe kolommen:\n",
      "['settlement_date', 'settlement_period', 'nd', 'tsd', 'england_wales_demand', 'embedded_wind_generation', 'embedded_wind_capacity', 'embedded_solar_generation', 'embedded_solar_capacity', 'non_bm_stor', 'pump_storage_pumping', 'scottish_transfer', 'ifa_flow', 'ifa2_flow', 'britned_flow', 'moyle_flow', 'east_west_flow', 'nemo_flow', 'nsl_flow', 'eleclink_flow', 'viking_flow', 'greenlink_flow']\n"
     ]
    }
   ],
   "source": [
    "# REQUIREMENT 1: Rename columns to lowercase and remove spaces\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "print(\"‚úÖ Nieuwe kolommen:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962a489",
   "metadata": {},
   "source": [
    "Alle 22 kolommen zijn nu consistent hernoemd naar lowercase met underscores. Dit omvat belangrijke variabelen zoals `ND` (de target die we willen voorspellen), embedded renewable generation (`embedded_wind_generation`, `embedded_solar_generation`), en verschillende interconnector flows die energie import/export met buurlanden weergeven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd1ef2",
   "metadata": {},
   "source": [
    "### 2.2 Date & Time parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ba7e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ settlement_date parsing summary (column: settlement_date):\n",
      "  - parsed with %Y-%m-%d: 153502 rows\n",
      "  - parsed with %Y/%m/%d: 0 rows\n",
      "  - parsed with %d-%b-%Y: 262992 rows\n",
      "  - parsed with %d-%B-%Y: 0 rows\n",
      "  - parsed with %d/%m/%Y: 0 rows\n",
      "  - parsed with %d.%m.%Y: 0 rows\n",
      "  - parsed with %d-%m-%Y: 0 rows\n",
      "  - parsed with %Y%m%d: 0 rows\n",
      "  - parsed with inferred: 17520 rows\n",
      "  - totaal parsed: 434014 / 434014\n",
      "  - niet geparsed (NaT): 0\n",
      "‚úÖ Time features created:\n",
      "  settlement_date  settlement_period  year  month  day  dayofweek  hour\n",
      "0      2001-01-01                  1  2001      1    1          0     0\n",
      "1      2001-01-01                  2  2001      1    1          0     0\n",
      "2      2001-01-01                  3  2001      1    1          0     1\n",
      "3      2001-01-01                  4  2001      1    1          0     1\n",
      "4      2001-01-01                  5  2001      1    1          0     2\n"
     ]
    }
   ],
   "source": [
    "# Opmerking: sommige CSV's gebruiken e.g. \"2009-01-01\", andere \"01-JAN-2009\" -> we proberen meerdere formats en rapporteren wat we vonden.\n",
    "date_col = None\n",
    "for c in df.columns:\n",
    "    if 'settlement' in c.lower() and 'date' in c.lower():\n",
    "        date_col = c\n",
    "        break\n",
    "if date_col is None:\n",
    "    raise KeyError(\"Geen settlement_date kolom gevonden in dataframe.\")\n",
    "\n",
    "s = df[date_col].astype(str).str.strip()\n",
    "\n",
    "# Te proberen formats (voorkomen van common cases incl. '01-JAN-2009')\n",
    "formats = [\n",
    "    \"%Y-%m-%d\",\n",
    "    \"%Y/%m/%d\",\n",
    "    \"%d-%b-%Y\",   # 01-JAN-2009\n",
    "    \"%d-%B-%Y\",   # 01-January-2009\n",
    "    \"%d/%m/%Y\",\n",
    "    \"%d.%m.%Y\",\n",
    "    \"%d-%m-%Y\",\n",
    "    \"%Y%m%d\",\n",
    "]\n",
    "\n",
    "parsed = pd.Series(pd.NaT, index=s.index, dtype=\"datetime64[ns]\")\n",
    "format_counts = {}\n",
    "\n",
    "# Try each explicit format\n",
    "for fmt in formats:\n",
    "    mask = parsed.isna() & s.notna()\n",
    "    if not mask.any():\n",
    "        break\n",
    "    try:\n",
    "        parsed_try = pd.to_datetime(s[mask], format=fmt, errors=\"coerce\")\n",
    "    except Exception:\n",
    "        parsed_try = pd.to_datetime(s[mask].replace(\" \", \"\"), format=fmt, errors=\"coerce\")\n",
    "    parsed.loc[mask] = parsed_try\n",
    "    count = parsed_try.notna().sum()\n",
    "    format_counts[fmt] = count\n",
    "\n",
    "# Laatste poging: inferentie (flexibeler, maar trager)\n",
    "mask = parsed.isna() & s.notna()\n",
    "if mask.any():\n",
    "    inferred = pd.to_datetime(s[mask], infer_datetime_format=True, dayfirst=True, errors=\"coerce\")\n",
    "    parsed.loc[mask] = inferred\n",
    "    format_counts[\"inferred\"] = inferred.notna().sum()\n",
    "\n",
    "total = len(s)\n",
    "parsed_count = parsed.notna().sum()\n",
    "unparsed_count = total - parsed_count\n",
    "\n",
    "print(f\"‚úÖ settlement_date parsing summary (column: {date_col}):\")\n",
    "for k, v in format_counts.items():\n",
    "    print(f\"  - parsed with {k}: {v} rows\")\n",
    "print(f\"  - totaal parsed: {parsed_count} / {total}\")\n",
    "print(f\"  - niet geparsed (NaT): {unparsed_count}\")\n",
    "\n",
    "if unparsed_count > 0:\n",
    "    sample_bad = s[parsed.isna()].drop_duplicates().tolist()[:10]\n",
    "    print(\"\\n‚ö†Ô∏è Voorbeelden van ongeldige / onbekende datumformaten (max 10):\")\n",
    "    for val in sample_bad:\n",
    "        print(f\"   - {val!r}\")\n",
    "\n",
    "# Assign parsed datetimes back to dataframe\n",
    "df[date_col] = parsed\n",
    "\n",
    "# Create additional time features (useful for modeling)\n",
    "df['year'] = df[date_col].dt.year\n",
    "df['month'] = df[date_col].dt.month\n",
    "df['day'] = df[date_col].dt.day\n",
    "df['dayofweek'] = df[date_col].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df['quarter'] = df[date_col].dt.quarter\n",
    "df['week'] = df[date_col].dt.isocalendar().week\n",
    "\n",
    "# Settlement period is 30-min blocks (1-48) ‚Äî bescherm tegen missing/incorrect values\n",
    "if 'settlement_period' in df.columns:\n",
    "    df['settlement_period'] = pd.to_numeric(df['settlement_period'], errors='coerce')\n",
    "    df['hour'] = ((df['settlement_period'] - 1) // 2).astype('Int64')\n",
    "else:\n",
    "    df['hour'] = pd.NA\n",
    "\n",
    "print(\"‚úÖ Time features created:\")\n",
    "print(df[[date_col, 'settlement_period', 'year', 'month', 'day', 'dayofweek', 'hour']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b2729",
   "metadata": {},
   "source": [
    "De settlement_date kolom bevat verschillende datumformaten doorheen de jaren omdat de databron kennelijk van format is veranderd. We hebben 153502 rijen met het %Y-%m-%d format (bijv. \"2001-01-01\") en 262992 rijen met het %d-%b-%Y format (bijv. \"01-Jan-2001\"). Door deze flexibele parsing aanpak kunnen we alle datums correct converteren naar datetime objecten. Daarnaast extraheren we ook nuttige temporele features zoals year, month, dayofweek, hour en quarter die later belangrijk zullen zijn voor onze modellen om seizoenspatronen en trends te detecteren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cdb9c",
   "metadata": {},
   "source": [
    "### 2.3 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c46158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Kolommen met missing values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>scottish_transfer</td>\n",
       "      <td>385680</td>\n",
       "      <td>88.863493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nsl_flow</td>\n",
       "      <td>315552</td>\n",
       "      <td>72.705489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eleclink_flow</td>\n",
       "      <td>315552</td>\n",
       "      <td>72.705489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>viking_flow</td>\n",
       "      <td>315552</td>\n",
       "      <td>72.705489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>greenlink_flow</td>\n",
       "      <td>315552</td>\n",
       "      <td>72.705489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embedded_solar_generation</td>\n",
       "      <td>140256</td>\n",
       "      <td>32.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>embedded_solar_capacity</td>\n",
       "      <td>140256</td>\n",
       "      <td>32.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ifa2_flow</td>\n",
       "      <td>140256</td>\n",
       "      <td>32.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>britned_flow</td>\n",
       "      <td>140256</td>\n",
       "      <td>32.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>east_west_flow</td>\n",
       "      <td>140256</td>\n",
       "      <td>32.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nemo_flow</td>\n",
       "      <td>140256</td>\n",
       "      <td>32.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>embedded_wind_generation</td>\n",
       "      <td>105168</td>\n",
       "      <td>24.231476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>embedded_wind_capacity</td>\n",
       "      <td>105168</td>\n",
       "      <td>24.231476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tsd</td>\n",
       "      <td>70128</td>\n",
       "      <td>16.158004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>moyle_flow</td>\n",
       "      <td>70128</td>\n",
       "      <td>16.158004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Column  Missing_Count  Missing_Percentage\n",
       "11          scottish_transfer         385680           88.863493\n",
       "18                   nsl_flow         315552           72.705489\n",
       "19              eleclink_flow         315552           72.705489\n",
       "20                viking_flow         315552           72.705489\n",
       "21             greenlink_flow         315552           72.705489\n",
       "7   embedded_solar_generation         140256           32.316008\n",
       "8     embedded_solar_capacity         140256           32.316008\n",
       "13                  ifa2_flow         140256           32.316008\n",
       "14               britned_flow         140256           32.316008\n",
       "16             east_west_flow         140256           32.316008\n",
       "17                  nemo_flow         140256           32.316008\n",
       "5    embedded_wind_generation         105168           24.231476\n",
       "6      embedded_wind_capacity         105168           24.231476\n",
       "3                         tsd          70128           16.158004\n",
       "15                 moyle_flow          70128           16.158004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Totaal aantal kolommen met missing data: 15\n"
     ]
    }
   ],
   "source": [
    "# REQUIREMENT 2: Look for NA values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing_Count': missing.values,\n",
    "    'Missing_Percentage': missing_pct.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"‚ö†Ô∏è Kolommen met missing values:\")\n",
    "display(missing_df)\n",
    "\n",
    "print(f\"\\nüìä Totaal aantal kolommen met missing data: {len(missing_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3fdd8d",
   "metadata": {},
   "source": [
    "De analyse toont dat verschillende kolommen substanti√´le hoeveelheden missende data bevatten, maar dit is verwacht en heeft een duidelijke oorzaak: deze features zijn pas later toegevoegd aan het meetsysteem. \n",
    "\n",
    "**Belangrijkste observaties:**\n",
    "- `scottish_transfer` heeft 89% missende waarden omdat deze interconnector pas later operationeel werd\n",
    "- Nieuwe interconnectors zoals `nsl_flow`, `eleclink_flow`, `viking_flow` en `greenlink_flow` (allen ~73% missing) zijn recent toegevoegd aan het energienetwerk\n",
    "- Embedded renewable data (`embedded_wind_generation`, `embedded_solar_generation` met 24-32% missing) werd pas vanaf een bepaald jaar systematisch bijgehouden naarmate deze technologie√´n mainstream werden\n",
    "- `tsd` (Transmission System Demand) en enkele andere flows hebben ook missing values uit vroegere jaren\n",
    "\n",
    "Deze missende waarden zijn geen data quality issues maar reflecteren de historische ontwikkeling van het UK energiesysteem. We zullen deze opvullen met 0, wat correct is omdat de afwezigheid van data betekent dat die capaciteit of connectie toen nog niet bestond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6a1d6",
   "metadata": {},
   "source": [
    "### 2.4 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ed387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing values na opvullen met 0: 0\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "df_clean = df_clean.fillna(0)\n",
    "\n",
    "print(\"‚úÖ Missing values na opvullen met 0:\", df_clean.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88f99c",
   "metadata": {},
   "source": [
    "Door alle missende waarden met 0 op te vullen hebben we nu een complete dataset van 434014 rijen zonder missing values. Deze imputation strategie is gerechtvaardigd omdat:\n",
    "1. Missende interconnector flows betekenen dat die verbinding nog niet operationeel was (dus effectief 0 MW flow)\n",
    "2. Missende embedded generation data betekent dat die capaciteit nog niet gemeten werd of verwaarloosbaar klein was\n",
    "3. Dit voorkomt dat we waardevolle historische data moeten weggooien\n",
    "\n",
    "Het alternatief (rijen met missing values verwijderen) zou betekenen dat we vooral recente data zouden overhouden, wat onze mogelijkheid om langetermijntrends te analyseren zou beperken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790c9d9",
   "metadata": {},
   "source": [
    "### 2.5 Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b9d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Categorical features:\n",
      "month                category\n",
      "dayofweek            category\n",
      "hour                 category\n",
      "quarter              category\n",
      "settlement_period    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['month', 'dayofweek', 'hour', 'quarter', 'settlement_period']\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_clean[col] = df_clean[col].astype('category')\n",
    "\n",
    "print(\"‚úÖ Categorical features:\")\n",
    "print(df_clean[categorical_features].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19dee5",
   "metadata": {},
   "source": [
    "We converteren temporele features naar categorische variabelen omdat ze cyclische patronen vertegenwoordigen. Een machine learning model moet begrijpen dat maand 12 (december) en maand 1 (januari) dichter bij elkaar liggen dan december en juni, ondanks de numerieke waarden. Door deze als categorie√´n te behandelen kunnen tree-based modellen zoals XGBoost deze cyclische patronen beter leren. Dit geldt vooral voor:\n",
    "- `month`: seizoenspatronen (winter vs zomer verbruik)\n",
    "- `dayofweek`: weekpatronen (werkdagen vs weekend)  \n",
    "- `hour`: dagelijkse patronen (piekuren vs daluren)\n",
    "- `settlement_period`: de specifieke half-uurlijkse periode binnen een dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48265e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extra features created:\n",
      "  dayofweek day_name  is_weekend\n",
      "0         0   Monday           0\n",
      "1         0   Monday           0\n",
      "2         0   Monday           0\n",
      "3         0   Monday           0\n",
      "4         0   Monday           0\n",
      "5         0   Monday           0\n",
      "6         0   Monday           0\n",
      "7         0   Monday           0\n",
      "8         0   Monday           0\n",
      "9         0   Monday           0\n"
     ]
    }
   ],
   "source": [
    "# Create readable labels voor dayofweek\n",
    "day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', \n",
    "             4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "df_clean['day_name'] = df_clean['dayofweek'].map(day_names)\n",
    "\n",
    "# Is weekend?\n",
    "df_clean['is_weekend'] = df_clean['dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"‚úÖ Extra features created:\")\n",
    "print(df_clean[['dayofweek', 'day_name', 'is_weekend']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4516056",
   "metadata": {},
   "source": [
    "We hebben twee nuttige afgeleide features toegevoegd:\n",
    "- **day_name**: Een leesbare versie van de dag (Monday, Tuesday, etc.) die visualisaties intu√Øtiever maakt\n",
    "- **is_weekend**: Een binaire indicator (0/1) die het onderscheid markeert tussen weekdagen en weekenden\n",
    "\n",
    "Deze weekend feature is bijzonder waardevol omdat elektriciteitsverbruik significant verschilt tussen werk- en weekenddagen. Op werkdagen zien we hogere pieken door kantoren, winkels en industrie, terwijl weekenden een vlakker verbruikspatroon tonen. Dit patroon is ook zichtbaar in de Christmas Day grafieken die we eerder lieten zien, waar een feestdag zich gedraagt als een weekend qua verbruiksprofiel.\n",
    "\n",
    "De dataset is nu volledig gereinigd en verrijkt met temporele features. In de volgende notebooks zullen we deze data gebruiken voor exploratory data analysis en het bouwen van voorspellingsmodellen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
